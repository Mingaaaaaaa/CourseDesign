import os
import sys
import threading

import cv2
from PyQt5.QtCore import QTimer, pyqtSignal
from PyQt5.QtGui import QImage, QPixmap, QTextCursor
from datetime import datetime
import multiprocessing

from store.config import ConfigStore
from utils.common import singleton
from view.mainDisplay import Ui_System
from PyQt5.QtWidgets import QMainWindow, QApplication


class MainPage(QMainWindow, Ui_System):
    logQueue = multiprocessing.Queue()  # æ—¥å¿—é˜Ÿåˆ—
    receiveLogSignal = pyqtSignal(str)  # LOG ä¿¡å·çŠ¶æ€

    def __init__(self, all_queues, classicPredictor, visionService, config):
        super(MainPage, self).__init__()
        self.setupUi(self)
        self.visionService = visionService
        self.config = config

        # æ‘„åƒå¤´å¼€å…³è®¾ç½®
        self.switchButton.clicked.connect(self.switch_camera)

        # æ‘„åƒå¤´å¸§è½®è¯¢
        self.timer = QTimer(self)
        self.timer.timeout.connect(self.update_frame)
        self.all_queues = all_queues

        # äººè„¸æ£€æµ‹è®¾ç½®
        self.openDetection.stateChanged.connect(self.open_detection)
        self.detectMethod.currentIndexChanged.connect(self.change_detect_method)

        # äººè„¸è¯†åˆ«è®¾ç½®
        self.openRecognition.stateChanged.connect(self.open_recognition)
        self.recogMethod.currentIndexChanged.connect(self.change_recog_method)
        self.classicPredictor = classicPredictor

        # æ—¥å¿—ç³»ç»Ÿ
        self.receiveLogSignal.connect(lambda log: self.logOutput(log))
        self.logOutputThread = threading.Thread(target=self.receiveLog, daemon=True)
        self.logOutputThread.start()

        # è®­ç»ƒæŒ‰é’®
        self.startTrainButton.clicked.connect(self.start_train)

        # äººè„¸æ³¨å†ŒæŒ‰é’®
        self.imgRegister.clicked.connect(self.register_face)
        self.visionService.registerResSignal.connect(lambda res: self.handleRegister(res))

        # è¯†åˆ«ç»“æœæ˜¾ç¤º
        self.visionService.resultSignal.connect(lambda result: self.recogOutput(result))

    def switch_camera(self):
        if not self.timer.isActive():
            self.visionService.start_camera()
            self.timer.start(1)
            self.switchButton.setText("æ‘„åƒå¤´å·²å¼€å¯")
            self.putLog("æ‘„åƒå¤´å·²å¼€å¯")
            self.switchButton.setDisabled(True)
        else:
            self.visionService.close_camera()
            self.timer.stop()
            self.switchButton.setText("æ‰“å¼€æ‘„åƒå¤´")

    def update_frame(self):
        config = ConfigStore()
        if self.classicPredictor.trained:
            config.set_config('recog_open_disabled', False)
            self.openRecognition.setDisabled(False)
            self.recogMethod.setDisabled(False)
        if not self.all_queues['display'].empty():
            frame = self.all_queues['display'].get()
            self.displayImage(frame, self.displayField)

    def displayImage(self, img, qlabel):
        # BGR -> RGB
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        # defaultï¼šThe image is stored using 8-bit indexes into a colormapï¼Œ for exampleï¼ša gray image
        qformat = QImage.Format_Indexed8

        if len(img.shape) == 3:  # rows[0], cols[1], channels[2]
            if img.shape[2] == 4:
                # The image is stored using a 32-bit byte-ordered RGBA format (8-8-8-8)
                # A: alpha channelï¼Œä¸é€æ˜åº¦å‚æ•°ã€‚å¦‚æœä¸€ä¸ªåƒç´ çš„alphaé€šé“æ•°å€¼ä¸º0%ï¼Œé‚£å®ƒå°±æ˜¯å®Œå…¨é€æ˜çš„
                qformat = QImage.Format_RGBA8888
            else:
                qformat = QImage.Format_RGB888

        # img.shape[1]ï¼šå›¾åƒå®½åº¦widthï¼Œimg.shape[0]ï¼šå›¾åƒé«˜åº¦heightï¼Œimg.shape[2]ï¼šå›¾åƒé€šé“æ•°
        # QImage.__init__ (self, bytes data, int width, int height, int bytesPerLine, Format format)
        # ä»å†…å­˜ç¼“å†²æµè·å–imgæ•°æ®æ„é€ QImageç±»
        # img.strides[0]ï¼šæ¯è¡Œçš„å­—èŠ‚æ•°ï¼ˆwidth*3ï¼‰,rgbä¸º3ï¼Œrgbaä¸º4
        # strides[0]ä¸ºæœ€å¤–å±‚(å³ä¸€ä¸ªäºŒç»´æ•°ç»„æ‰€å çš„å­—èŠ‚é•¿åº¦)ï¼Œstrides[1]ä¸ºæ¬¡å¤–å±‚ï¼ˆå³ä¸€ç»´æ•°ç»„æ‰€å å­—èŠ‚é•¿åº¦ï¼‰ï¼Œstrides[2]ä¸ºæœ€å†…å±‚ï¼ˆå³ä¸€ä¸ªå…ƒç´ æ‰€å å­—èŠ‚é•¿åº¦ï¼‰
        # ä»é‡Œå¾€å¤–çœ‹ï¼Œstrides[2]ä¸º1ä¸ªå­—èŠ‚é•¿åº¦ï¼ˆuint8ï¼‰ï¼Œstrides[1]ä¸º3*1ä¸ªå­—èŠ‚é•¿åº¦ï¼ˆ3å³rgb 3ä¸ªé€šé“ï¼‰
        # strides[0]ä¸ºwidth*3ä¸ªå­—èŠ‚é•¿åº¦ï¼Œwidthä»£è¡¨ä¸€è¡Œæœ‰å‡ ä¸ªåƒç´ 

        outImage = QImage(img, img.shape[1], img.shape[0], img.strides[0], qformat)
        qlabel.setPixmap(QPixmap.fromImage(outImage))
        qlabel.setScaledContents(True)  # å›¾ç‰‡è‡ªé€‚åº”å¤§å°

    def open_detection(self):
        if self.openDetection.isChecked():
            self.putLog("âœ…ï¸äººè„¸æ£€æµ‹å·²å¼€å¯")
            self.config.set_config('face_detect', True)
        else:
            self.putLog("ğŸ›‘äººè„¸æ£€æµ‹å·²å…³é—­")
            self.config.set_config('face_detect', False)

    def change_detect_method(self):
        self.putLog(f"åˆ‡æ¢äººè„¸æ£€æµ‹ç®—æ³•: {self.detectMethod.currentText()}")
        self.config.set_config('detect_method', self.detectMethod.currentIndex())

    def open_recognition(self):
        if self.openRecognition.isChecked():
            self.putLog("âœ…ï¸äººè„¸è¯†åˆ«å·²å¼€å¯")
            self.config.set_config('recog_open', True)
        else:
            self.putLog("ğŸ›‘äººè„¸è¯†åˆ«å·²å…³é—­")
            self.config.set_config('recog_open', False)

    def change_recog_method(self):
        self.putLog(f"åˆ‡æ¢äººè„¸è¯†åˆ«ç®—æ³•: {self.recogMethod.currentText()}")
        self.config.set_config('recog_method', self.recogMethod.currentIndex())

    def putLog(self, log):
        self.logQueue.put(log)

    def receiveLog(self):
        """
        ç³»ç»Ÿæ—¥å¿—æœåŠ¡å¸¸é©»ï¼Œæ¥æ”¶å¹¶å¤„ç†ç³»ç»Ÿæ—¥å¿—
        :return:
        """
        while True:
            data = self.logQueue.get()
            if data:
                self.receiveLogSignal.emit(data)
            else:
                continue

    def recogOutput(self, result):
        self.resultLabel.setText(result)
        picList = os.listdir(os.path.join('dataset', 'full', result))
        resPic = cv2.imread(os.path.join('dataset', 'full', result, picList[0]))
        self.displayImage(resPic, self.resultFace)

    def logOutput(self, log):
        """
        LOGè¾“å‡º
        :param log:
        :return:
        """
        # è·å–å½“å‰ç³»ç»Ÿæ—¶é—´
        time = datetime.now().strftime('[%Y/%m/%d %H:%M:%S]')
        log = time + ' ' + log + '\n'

        self.logText.moveCursor(QTextCursor.End)
        self.logText.insertPlainText(log)
        self.logText.ensureCursorVisible()  # è‡ªåŠ¨æ»šå±

    def start_train(self):
        self.classicPredictor.train(self.putLog)
        self.putLog("å¼€å§‹è®­ç»ƒ")

    def register_face(self):
        """
        å¼‚æ­¥è¯·æ±‚http://114.116.250.18:8000/registeræ¥å£
        æ¥å£å‚æ•°ä¸º name, photo
        """
        name = self.nameInput.text()
        if not name:
            self.putLog("è¯·è¾“å…¥å§“å")
            return
        self.putLog("å¼€å§‹æ³¨å†Œ")
        self.putLog(f"å§“å: {name}")
        self.putLog("è¯·ç¨å...")
        self.imgRegister.setDisabled(True)
        self.visionService.vision_face_register(name)

    def handleRegister(self, res):
        if res == 'æ³¨å†ŒæˆåŠŸ':
            self.putLog("æ³¨å†ŒæˆåŠŸ")
        else:
            self.putLog("æ³¨å†Œå¤±è´¥")
        self.imgRegister.setDisabled(False)
